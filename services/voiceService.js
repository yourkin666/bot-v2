const OpenAI = require('openai');
const fs = require('fs');
const path = require('path');
const config = require('../config');

class VoiceService {
  constructor() {
    // åˆå§‹åŒ–Whisperå®¢æˆ·ç«¯ï¼ˆä¸“é—¨ç”¨äºè¯­éŸ³è¯†åˆ«ï¼‰
    this.whisperClient = new OpenAI({
      apiKey: config.whisper.apiKey,
      baseURL: config.whisper.baseURL
    });
    
    // åˆå§‹åŒ–å¯¹è¯å®¢æˆ·ç«¯ï¼ˆç”¨äºç¿»è¯‘ï¼Œä½¿ç”¨ç¡…åŸºæµåŠ¨ï¼‰
    this.chatClient = new OpenAI({
      apiKey: config.openai.apiKey,
      baseURL: config.openai.baseURL
    });
    
    // ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨
    this.uploadPath = config.voice.uploadPath;
    if (!fs.existsSync(this.uploadPath)) {
      fs.mkdirSync(this.uploadPath, { recursive: true });
    }
  }

  // è¯­éŸ³è½¬æ–‡å­—
  async speechToText(audioFilePath) {
    try {
      console.log('ğŸ™ï¸ å¼€å§‹è¯­éŸ³è¯†åˆ«ï¼Œæ–‡ä»¶è·¯å¾„:', audioFilePath);
      
      // æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
      if (!fs.existsSync(audioFilePath)) {
        throw new Error('éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨');
      }

      // ä½¿ç”¨OpenAIçš„Whisper APIè¿›è¡Œè¯­éŸ³è¯†åˆ«
      const transcription = await this.whisperClient.audio.transcriptions.create({
        file: fs.createReadStream(audioFilePath),
        model: "whisper-1",
        language: "zh", // æŒ‡å®šä¸­æ–‡ï¼Œä½†ä¹Ÿå¯ä»¥è‡ªåŠ¨è¯†åˆ«å…¶ä»–è¯­è¨€
      });

      console.log('ğŸ™ï¸ è¯­éŸ³è¯†åˆ«ç»“æœ:', transcription.text);
      
      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      this.cleanupTempFile(audioFilePath);
      
      return {
        success: true,
        text: transcription.text,
        language: 'è‡ªåŠ¨è¯†åˆ«'
      };

    } catch (error) {
      console.error('è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
      
      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆå³ä½¿å‡ºé”™ä¹Ÿè¦æ¸…ç†ï¼‰
      this.cleanupTempFile(audioFilePath);
      
      return {
        success: false,
        error: 'è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•'
      };
    }
  }

  // ç¿»è¯‘æ–‡æœ¬ä¸ºä¸­æ–‡
  async translateToChinese(text) {
    try {
      console.log('ğŸŒ å¼€å§‹ç¿»è¯‘æ–‡æœ¬:', text);
      
      // å…ˆæ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯ä¸­æ–‡
      if (this.isChinese(text)) {
        console.log('ğŸŒ æ–‡æœ¬å·²ç»æ˜¯ä¸­æ–‡ï¼Œæ— éœ€ç¿»è¯‘');
        return {
          success: true,
          originalText: text,
          translatedText: text,
          isAlreadyChinese: true
        };
      }

      // ä½¿ç”¨AIè¿›è¡Œç¿»è¯‘
      const response = await this.chatClient.chat.completions.create({
        model: config.openai.model,
        messages: [
          {
            role: 'system',
            content: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹ã€‚è¯·å°†ç”¨æˆ·è¾“å…¥çš„ä»»ä½•è¯­è¨€çš„æ–‡æœ¬ç¿»è¯‘æˆç®€ä½“ä¸­æ–‡ã€‚åªè¿”å›ç¿»è¯‘ç»“æœï¼Œä¸è¦æ·»åŠ é¢å¤–çš„è§£é‡Šã€‚'
          },
          {
            role: 'user',
            content: `è¯·å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆä¸­æ–‡ï¼š${text}`
          }
        ],
        temperature: 0.3,
        max_tokens: 500
      });

      const translatedText = response.choices[0].message.content;
      console.log('ğŸŒ ç¿»è¯‘ç»“æœ:', translatedText);

      return {
        success: true,
        originalText: text,
        translatedText: translatedText,
        isAlreadyChinese: false
      };

    } catch (error) {
      console.error('ç¿»è¯‘å¤±è´¥:', error);
      return {
        success: false,
        error: 'ç¿»è¯‘å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•',
        originalText: text
      };
    }
  }

  // å®Œæ•´çš„è¯­éŸ³å¤„ç†æµç¨‹ï¼šå½•éŸ³ -> è¯†åˆ« -> ç¿»è¯‘
  async processVoice(audioFilePath) {
    try {
      console.log('ğŸ¤ å¼€å§‹å¤„ç†è¯­éŸ³æ–‡ä»¶:', audioFilePath);
      
      // ç¬¬ä¸€æ­¥ï¼šè¯­éŸ³è½¬æ–‡å­—
      const speechResult = await this.speechToText(audioFilePath);
      if (!speechResult.success) {
        return speechResult;
      }

      // ç¬¬äºŒæ­¥ï¼šç¿»è¯‘ä¸ºä¸­æ–‡
      const translateResult = await this.translateToChinese(speechResult.text);
      if (!translateResult.success) {
        return {
          success: false,
          error: translateResult.error,
          recognizedText: speechResult.text
        };
      }

      // è¿”å›å®Œæ•´ç»“æœ
      return {
        success: true,
        originalText: speechResult.text,
        translatedText: translateResult.translatedText,
        isAlreadyChinese: translateResult.isAlreadyChinese,
        language: speechResult.language,
        timestamp: new Date().toISOString()
      };

    } catch (error) {
      console.error('è¯­éŸ³å¤„ç†å¤±è´¥:', error);
      return {
        success: false,
        error: 'è¯­éŸ³å¤„ç†å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•'
      };
    }
  }

  // æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡
  isChinese(text) {
    const chineseRegex = /[\u4e00-\u9fff]/;
    const chineseChars = text.match(/[\u4e00-\u9fff]/g);
    const totalChars = text.replace(/\s/g, '').length;
    
    // å¦‚æœä¸­æ–‡å­—ç¬¦å æ¯”è¶…è¿‡30%ï¼Œè®¤ä¸ºæ˜¯ä¸­æ–‡
    return chineseChars && (chineseChars.length / totalChars) > 0.3;
  }

  // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
  cleanupTempFile(filePath) {
    try {
      if (fs.existsSync(filePath)) {
        fs.unlinkSync(filePath);
        console.log('ğŸ§¹ å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶:', filePath);
      }
    } catch (error) {
      console.error('æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥:', error);
    }
  }

  // éªŒè¯éŸ³é¢‘æ–‡ä»¶æ ¼å¼
  validateAudioFile(file) {
    const allowedFormats = config.voice.allowedFormats;
    const maxSize = config.voice.maxFileSize;
    
    if (!allowedFormats.includes(file.mimetype)) {
      return {
        valid: false,
        error: `ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼ã€‚æ”¯æŒçš„æ ¼å¼ï¼š${allowedFormats.join(', ')}`
      };
    }
    
    if (file.size > maxSize) {
      return {
        valid: false,
        error: `æ–‡ä»¶è¿‡å¤§ã€‚æœ€å¤§æ”¯æŒ ${Math.round(maxSize / 1024 / 1024)}MB`
      };
    }
    
    return { valid: true };
  }
}

module.exports = new VoiceService(); 